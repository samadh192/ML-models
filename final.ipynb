{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hsnhhnclc7I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('diabetes2.csv')"
      ],
      "metadata": {
        "id": "PH-SvFn3lfjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "cvN-jFq9lhZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "gWkr882VljIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
        "# df = df.dropna()\n",
        "# df.info()\n",
        "\n",
        "df['Glucose'].fillna(df['Glucose'].mean(), inplace = True)\n",
        "df['BloodPressure'].fillna(df['BloodPressure'].mean(), inplace = True)\n",
        "df['SkinThickness'].fillna(df['SkinThickness'].mean(), inplace = True)\n",
        "df['Insulin'].fillna(df['Insulin'].mean(), inplace = True)\n",
        "df['BMI'].fillna(df['BMI'].mean(), inplace = True)"
      ],
      "metadata": {
        "id": "yKmgnOP_llMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_correlation = (df.corr()['price']).sort_values(key=abs)\n",
        "print(price_correlation)\n",
        "df.drop(['BloodPressure','DiabetesPedigreeFunction'], inplace = True, axis = 1)"
      ],
      "metadata": {
        "id": "_HLad51anefO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cut'].unique()\n",
        "df = pd.get_dummies(df, columns=['cut', 'color', 'clarity'])\n",
        "df.replace({False: 0, True: 1}, inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "XahMogw7n2pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df,column):\n",
        "  Q1 = df[column].quantile(0.25)\n",
        "  Q3 = df[column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower = Q1 - 1.5*IQR\n",
        "  upper = Q3 + 1.5*IQR\n",
        "  return df[(df[column] >= lower) & (df[column] <= upper)]\n",
        "#outliers have been removed\n",
        "outlier_columns = ['max heart rate','oldpeak']\n",
        "for column in outlier_columns:\n",
        "  df2 = remove_outliers(df1,column)\n",
        "df2.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "TIotHbSZoKc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_scale = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
        "numeric_data = df[columns_to_scale]\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(numeric_data)\n",
        "scaled_data = scaler.transform(numeric_data)\n",
        "df[columns_to_scale] = scaled_data"
      ],
      "metadata": {
        "id": "C37PtJnjns9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=50)"
      ],
      "metadata": {
        "id": "KsF83cstokrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Outcome']\n",
        "X = df.drop('Outcome', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 50)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "4eK3O-49ols6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    # 'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=50),\n",
        "    'Logistic Regression': LogisticRegression()\n",
        "}\n",
        "\n",
        "# Define hyperparameters grid for each classifier\n",
        "# param_grids = {\n",
        "#     'SVM': {\n",
        "#         'C': [0.1, 1, 10],\n",
        "#         'gamma': ['scale', 'auto'],\n",
        "#         'kernel': ['rbf', 'linear']\n",
        "#     },\n",
        "#     'KNN': {\n",
        "#         'n_neighbors': [3, 5, 7],\n",
        "#         'weights': ['uniform', 'distance']\n",
        "#     },\n",
        "#     'Random Forest': {\n",
        "#         'n_estimators': [50, 100],\n",
        "#         'max_depth': [None, 10],\n",
        "#         'min_samples_split': [2, 5],\n",
        "#         'max_features': ['sqrt', 'log2']\n",
        "#     },\n",
        "#     'Logistic Regression': {\n",
        "#         'solver': ['saga', 'liblinear'],\n",
        "#         'penalty': ['l1', 'l2'],\n",
        "#         'C': [0.1, 1, 10],\n",
        "#         'max_iter': [100, 500]\n",
        "#     }\n",
        "# }\n",
        "\n",
        "param_grids = {\n",
        "    # 'SVM': {\n",
        "    #     'C': [0.1, 1, 10, 100, 1000],\n",
        "    #     'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 'scale', 'auto'],\n",
        "    #     'kernel': ['rbf','linear']\n",
        "    # },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3,4,5,6,7,8,9,10],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "      'n_estimators': [50, 100, 150],\n",
        "      'max_depth': [None, 10, 20],\n",
        "      'min_samples_split': [2, 5, 10],\n",
        "      'max_features': ['sqrt', 'log2']\n",
        "    },\n",
        "    # 'HistGradientBoosting': {\n",
        "    #     'learning_rate': [0.1, 0.01, 0.001],\n",
        "    #     'max_iter': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "    # },\n",
        "    'Logistic Regression':{'solver': ['saga', 'liblinear'],\n",
        "                  'penalty': ['l1','l2'],\n",
        "                 'C': [0.001,0.01,0.1,1,10,100,1000],\n",
        "                  'max_iter' : [10,100,500]}\n",
        "}\n",
        "\n",
        "\n",
        "# param_grids = {\n",
        "#     'SVM': {\n",
        "#         'C': [0.1],\n",
        "#         'gamma': ['scale', 'auto'],\n",
        "#         'kernel': ['rbf', 'linear']\n",
        "#     },\n",
        "#     'KNN': {\n",
        "#         'n_neighbors': [3, 5, 7],\n",
        "#         'weights': ['uniform', 'distance']\n",
        "#     },\n",
        "#     'Random Forest': {\n",
        "#         'n_estimators': [50, 100],\n",
        "#         'max_depth': [None, 10],\n",
        "#         'min_samples_split': [2, 5],\n",
        "#         'max_features': ['sqrt', 'log2']\n",
        "#     },\n",
        "#     'Logistic Regression': {\n",
        "#         'solver': ['saga', 'liblinear'],\n",
        "#         'penalty': ['l1', 'l2'],\n",
        "#         'C': [0.1, 1, 10],\n",
        "#         'max_iter': [100, 500]\n",
        "#     }\n",
        "# }"
      ],
      "metadata": {
        "id": "vXXGYOl0op6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, classifier in classifiers.items():\n",
        "    print(\"Training: \", name)\n",
        "    gridSearch = GridSearchCV(estimator=classifier, param_grid=param_grids[name], cv=5, n_jobs=-1)\n",
        "    gridSearch.fit(X_train, y_train)\n",
        "    results[name] = gridSearch.best_estimator_\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "XjAmcgmNo3NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in results.items():\n",
        "    print(\"\\nResults for\", name)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "rWlprZ7So8RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False]\n",
        "}\n",
        "gridSearch = GridSearchCV(estimator=LinearRegression(), param_grid=parameters, cv=5, n_jobs=-1)\n",
        "gridSearch.fit(X_train, y_train)\n",
        "bestModel = gridSearch.best_estimator_\n",
        "y_pred = bestModel.predict(X_test)\n",
        "bestModel_score = bestModel.score(X_test, y_test)\n",
        "print(bestModel_score)"
      ],
      "metadata": {
        "id": "H0Js7AlbpFll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "metadata": {
        "id": "ZeYFU0QVpR9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# add input layer size to the first hidden layer\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "MkGKIyY7pSmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BQpY48sppXSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "# stochastic gradient descent optimizer\n",
        "sgd_optimizer = keras.optimizers.Adam()\n",
        "# categoricall crossentropy loss function\n",
        "cc_loss = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model.compile(optimizer=sgd_optimizer, loss=cc_loss, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Sc_c06alpaFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "Lcs5h978pdEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "TnkBIspvpfdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(sparse_output=False).fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "quNDKUFMphbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=1)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "Lam80ySGpjjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MFS5vCKMpnfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "predictions = np.argmax(y_pred, axis = 1)\n",
        "correct = np.argmax(y_test, axis = 1)\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(correct, predictions))\n",
        "\n",
        "# Compute additional metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(correct, predictions))"
      ],
      "metadata": {
        "id": "1yppLhWkpqaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}